{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Inroduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are collection of functions and methods that allows for performance of many actions without writing the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\elton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# reading in data\n",
    "import re\n",
    "import string\n",
    "import numpy as np \n",
    "import random\n",
    "import pandas as pd \n",
    "\n",
    "#Vissualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from plotly import graph_objs as go # pip install plotly==4.8.1\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator #pip install wordcloud\n",
    "\n",
    "#Preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import spacy\n",
    "import random\n",
    "from spacy.util import compounding\n",
    "from spacy.util import minibatch\n",
    "\n",
    "#modeling\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#csv paths\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a helper Function which generates random colors which will be used to give different colors to the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_colours(number_of_colors):\n",
    "    '''\n",
    "    Simple function for random colours generation.\n",
    "    Input:\n",
    "        number_of_colors - integer value indicating \n",
    "        the number of colours which are going to be \n",
    "        generated.\n",
    "    Output:\n",
    "        Color in the following format: ['#E86DA4'] .\n",
    "    '''\n",
    "    colors = []\n",
    "    for i in range(number_of_colors):\n",
    "        colors.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Getting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is given in the format csv files, pandas are used to import and convert the csv files to panda data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "ss_df = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Desciption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is just the over view of the data frames and thier contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This is the Train data frame')\n",
    "print(train_df.head(4))\n",
    "print('')\n",
    "print('This is the Test data frame')\n",
    "print(test_df.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both data frames have message and tweetid columns, the difference is that the train data frame has sentiment column and test data frame does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the Sample submission data frame, which is just a guide on how the submission should be made. It has only two columns, the tweetid and the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('___basic info of the train data___')\n",
    "print(train_df.info())\n",
    "print('Dataset size:', train_df.shape)\n",
    "print('Columns are:',train_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the train dataframe basic information, it shows that there are 15819 entries, 0 to 15818.The sentiment and the tweetid are intigers and the sentiment is an object. so the shape is 15819 entries by 3 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Exploratory Data Analysis on Raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Taking a closer look at the distribution of tweeter messages in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_df.groupby('sentiment').count()['message'].reset_index().sort_values(by='message',ascending=False)\n",
    "temp['percentage'] = round((temp['message']/temp['message'].sum())*100,0)\n",
    "temp.style.background_gradient(cmap='Purples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.funnel(temp, x='sentiment', y='message',color='sentiment')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table and the funnel display the count and percentage of message in the train data frame. Sentiment 1 has the highest count of message of 8530 which is 54% of the whole message and negative sentiment (-1) has the lowest count of 1296 which is 8% of the whole messages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Wordcloud Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a popular visualization of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_colwidth', 60)\n",
    "# visualising the messages \n",
    "df_senti1 = train_df[train_df['sentiment']==1]\n",
    "df_senti0 = train_df[train_df['sentiment']==0]\n",
    "df_senti_neg1 = train_df[train_df['sentiment']==-1]\n",
    "df_senti2 = train_df[train_df['sentiment']==2]\n",
    "tweet_All = \" \".join(review for review in train_df.message)\n",
    "tweet_senti1 = \" \".join(review for review in df_senti1.message)\n",
    "tweet_senti0 = \" \".join(review for review in df_senti0.message)\n",
    "tweet_senti_neg1 = \" \".join(review for review in df_senti_neg1.message)\n",
    "tweet_senti2 = \" \".join(review for review in df_senti2.message)\n",
    "\n",
    "fig, ax = plt.subplots(5, 1, figsize  = (65,65))\n",
    "# Create and generate a word cloud image:\n",
    "wordcloud_ALL = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_All)\n",
    "wordcloud_1 = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_senti1)\n",
    "wordcloud_0 = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_senti0)\n",
    "wordcloud_neg1 = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_senti_neg1)\n",
    "wordcloud_2 = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_senti2)\n",
    "\n",
    "# Display the generated image:\n",
    "ax[0].imshow(wordcloud_ALL, interpolation='bilinear')\n",
    "ax[0].set_title('All Tweets', fontsize=50)\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(wordcloud_1, interpolation='bilinear')\n",
    "ax[1].set_title('Tweets under Pro Class 1',fontsize=50)\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(wordcloud_0, interpolation='bilinear')\n",
    "ax[2].set_title('Tweets under Neutral Class 0',fontsize=50)\n",
    "ax[2].axis('off')\n",
    "ax[3].imshow(wordcloud_neg1, interpolation='bilinear')\n",
    "ax[3].set_title('Tweets under Anti Class -1',fontsize=50)\n",
    "ax[3].axis('off')\n",
    "ax[4].imshow(wordcloud_2, interpolation='bilinear')\n",
    "ax[4].set_title('Tweets under News Class 2',fontsize=50)\n",
    "ax[4].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Wordcloud Visualization display top 100 words from the whole message column and semtimentwise.The size of the words is related to how frequent the word occured in the messages,the bigger the word the more frequent it appeared in the messages.\n",
    "\n",
    "* All tweet message \n",
    "some of the most occuring words in all tweets are 'climate change, is, https, CO, RT and global warming'\n",
    "\n",
    "* Tweets messages under Pro sentiment(1)\n",
    "most common words here 'global warming, https, RT,CO Believe, doesnt believe'\n",
    "\n",
    "* tweets under sentiment 0 the Neutral\n",
    "most common words are global warming, CO, Https,Rt\n",
    "* tweets under sentiment -1 the Anti\n",
    "common words oare 'Co,RT,Https, Trump, man  made, global warming'\n",
    "* tweets under sentiment 2 the News\n",
    "common words are 'Co,RT,Https, Trump, global warming, via\n",
    "\n",
    "This is interesting because some of the words such as belive ,Trump are only common in certain sentiments. the RT refers to retweets and the https is the hyper link on the tweet.\n",
    "\n",
    "It can be concluded that there are lot of retweets in the data frame. Retweets are just repetions of an original post on twitter shared by different users. This means that a person sharing the retweet is just supporting the origional post. the name Trump which is the name of US president seems to appear more often awell. Words such as climate, global warming related to the problem statement of this project unlike other words such as 'via, is, https' which are frequently occuring from the tweets.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking top common words by count\n",
    "\n",
    "diving deeper to check count of some common words from the tweet messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking top 20 common words from all tweets\n",
    "train_df['temp_list'] = train_df['message'].apply(lambda x:str(x).split())\n",
    "top = Counter([item for sublist in train_df['temp_list'] for item in sublist])\n",
    "temp = pd.DataFrame(top.most_common(20))\n",
    "temp.columns = ['Common_words','count']\n",
    "temp.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Raw message', orientation='h', \n",
    "             width=700, height=700,color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Climate RT and Change are still top most occuring words in the tweets.Whats new here is that common words such as 'The,to, of ,is ,a'are now showeing to be appearing more often aswell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the sentiments so that each sentiment can be explored\n",
    "Pro = train_df[train_df['sentiment']==1]\n",
    "Anti = train_df[train_df['sentiment']== -1]\n",
    "Neutral = train_df[train_df['sentiment']==0]\n",
    "News = train_df[train_df['sentiment']== 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MosT common positive words(Pro)\n",
    "top = Counter([item for sublist in Pro['temp_list'] for item in sublist])\n",
    "temp_positive = pd.DataFrame(top.most_common(20))\n",
    "temp_positive.columns = ['Common_words','count']\n",
    "temp_positive.style.background_gradient(cmap='Oranges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Data cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MosT common negative words(Anti)\n",
    "top = Counter([item for sublist in Anti['temp_list'] for item in sublist])\n",
    "temp_negative = pd.DataFrame(top.most_common(20))\n",
    "temp_negative = temp_negative.iloc[1:,:]\n",
    "temp_negative.columns = ['Common_words','count']\n",
    "temp_negative.style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MosT common words in Neutral sentiment\n",
    "top = Counter([item for sublist in Neutral['temp_list'] for item in sublist])\n",
    "temp_neutral = pd.DataFrame(top.most_common(20))\n",
    "temp_neutral = temp_neutral.loc[1:,:]\n",
    "temp_neutral.columns = ['Common_words','count']\n",
    "temp_neutral.style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MosT common words in News sentiment\n",
    "top = Counter([item for sublist in News['temp_list'] for item in sublist])\n",
    "temp_neutral = pd.DataFrame(top.most_common(20))\n",
    "temp_neutral = temp_neutral.loc[1:,:]\n",
    "temp_neutral.columns = ['Common_words','count']\n",
    "temp_neutral.style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Data cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    '''The Function change contraction words to thier full format(eg did'nt ti did not), lowers \n",
    "    all text to lower case format, makes \n",
    "    text lowercase,removes links(https), \n",
    "    removes punctuation(!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~)\n",
    "    , removes words containing numbers and words that are attachec with #tag.'''\n",
    "    \n",
    "    contractions_dict = {\"ain't\": \"am not / are not / is not / has not / have not\",\n",
    "                         \"aren't\": \"are not / am not\",\"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
    "                         \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
    "                         \"couldn't've\": \"could not have\",\"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
    "                         \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "                         \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he had / he would\",\n",
    "                         \"he'd've\": \"he would have\",\"he'll\": \"he shall / he will\",\n",
    "                         \"he'll've\": \"he shall have / he will have\",\"he's\": \"he has / he is\",\n",
    "                         \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
    "                         \"how's\": \"how has / how is / how does\",\"I'd\": \"I had / I would\",\n",
    "                         \"I'd've\": \"I would have\",\"I'll\": \"I shall / I will\",\n",
    "                         \"I'll've\": \"I shall have / I will have\",\"I'm\": \"I am\",\"I've\": \"I have\",\n",
    "                         \"isn't\": \"is not\",\"it'd\": \"it had / it would\",\"it'd've\": \"it would have\",\n",
    "                         \"it'll\": \"it shall / it will\",\"it'll've\": \"it shall have / it will have\",\n",
    "                         \"it's\": \"it has / it is\",\"let's\": \"let us\",\"ma'am\": \"madam\",\"mayn't\": \"may not\",\n",
    "                         \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\n",
    "                         \"must've\": \"must have\",\"mustn't\": \"must not\",\"mustn't've\": \"must not have\",\n",
    "                         \"needn't\": \"need not\",\"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                         \"oughtn't\": \"ought not\",\"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\n",
    "                         \"sha'n't\": \"shall not\",\"shan't've\": \"shall not have\",\"she'd\": \"she had / she would\",\n",
    "                         \"she'd've\": \"she would have\",\n",
    "                         \"she'll\": \"she shall / she will\",\"she'll've\": \"she shall have / she will have\",\n",
    "                         \"she's\": \"she has / she is\",\"should've\": \"should have\",\"shouldn't\": \"should not\",\n",
    "                         \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\"so's\": \"so as / so is\",\n",
    "                         \"that'd\": \"that would / that had\",\"that'd've\": \"that would have\",\"that's\": \"that has / that is\",\n",
    "                         \"there'd\": \"there had / there would\",\"there'd've\": \"there would have\",\n",
    "                         \"there's\": \"there has / there is\",\"they'd\": \"they had / they would\",\n",
    "                         \"they'd've\": \"they would have\",\"they'll\": \"they shall / they will\",\n",
    "                         \"they'll've\": \"they shall have / they will have\",\"they're\": \"they are\",\n",
    "                         \"they've\": \"they have\",\"to've\": \"to have\",\"wasn't\": \"was not\",\n",
    "                         \"we'd\": \"we had / we would\",\"we'd've\": \"we would have\",\n",
    "                         \"we'll\": \"we will\",\"we'll've\": \"we will have\",\"we're\": \"we are\",\"we've\": \"we have\",\n",
    "                         \"weren't\": \"were not\",\"what'll\": \"what shall / what will\",\n",
    "                         \"what'll've\": \"what shall have / what will have\",\n",
    "                         \"what're\": \"what are\",\"what's\": \"what has / what is\",\n",
    "                         \"what've\": \"what have\",\"when's\": \"when has / when is\",\"when've\": \"when have\",\n",
    "                         \"where'd\": \"where did\",\"where's\": \"where has / where is\",\n",
    "                         \"where've\": \"where have\",\"who'll\": \"who shall / who will\",\n",
    "                         \"who'll've\": \"who shall have / who will have\",\n",
    "                         \"who's\": \"who has / who is\",\"who've\": \"who have\",\n",
    "                         \"why's\": \"why has / why is\",\"why've\": \"why have\",\"will've\": \"will have\",\n",
    "                         \"won't\": \"will not\",\"won't've\": \"will not have\",\"would've\": \"would have\",\n",
    "                         \"wouldn't\": \"would not\",\"wouldn't've\": \"would not have\",\n",
    "                         \"y'all\": \"you all\",\"y'all'd\": \"you all would\",\n",
    "                         \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "                         \"y'all've\": \"you all have\",\"you'd\": \"you had / you would\",\n",
    "                         \"you'd've\": \"you would have\",\"you'll\": \"you shall / you will\",\n",
    "                         \"you'll've\": \"you shall have / you will have\",\"you're\": \"you are\",\n",
    "                         \"you've\": \"you have\"}\n",
    "\n",
    "    for word in text.split():\n",
    "        if word.lower() in contractions_dict:\n",
    "            text = text.replace(word,contractions_dict[word.lower()])\n",
    "    text = str(text).lower() #Make text lowercase\n",
    "    text = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",text).split())# remove @user, #word and link\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) ##remove punctuation\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = ''.join([i for i in text[:] if not i.isdigit()]) #remove numbers\n",
    "    return text\n",
    "\n",
    "train_df['clean_message'] = train_df['message'].apply(lambda x: cleaning(x))\n",
    "test_df['clean_message'] = test_df['message'].apply(lambda x: cleaning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>clean_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>polyscimajor epa chief does not think carbon d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>it has it is not like we lack evidence of anth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>rt researchers say we have three years to act ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>wired  was a pivotal year in the war on climat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>rt it has it is  and a racist sexist climate c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "\n",
       "                                       clean_message  \n",
       "0  polyscimajor epa chief does not think carbon d...  \n",
       "1  it has it is not like we lack evidence of anth...  \n",
       "2  rt researchers say we have three years to act ...  \n",
       "3  wired  was a pivotal year in the war on climat...  \n",
       "4  rt it has it is  and a racist sexist climate c...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1. Lemmatisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of Lemmatization is to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "def lemmatizer(text):        \n",
    "    sent = []\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        sent.append(word.lemma_)\n",
    "    return \" \".join(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"lemmaa\"] =train_df.apply(lambda x: lemmatizer(x['clean_message']), axis=1)\n",
    "test_df[\"lemmaa\"] =test_df.apply(lambda x: lemmatizer(x['clean_message']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>clean_message</th>\n",
       "      <th>lemmaa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>polyscimajor epa chief does not think carbon d...</td>\n",
       "      <td>polyscimajor epa chief do not think carbon dio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>it has it is not like we lack evidence of anth...</td>\n",
       "      <td>-PRON- have -PRON- be not like -PRON- lack evi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>rt researchers say we have three years to act ...</td>\n",
       "      <td>rt researcher say -PRON- have three year to ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>wired  was a pivotal year in the war on climat...</td>\n",
       "      <td>wired   be a pivotal year in the war on climat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>rt it has it is  and a racist sexist climate c...</td>\n",
       "      <td>rt -PRON- have -PRON- be   and a racist sexist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "\n",
       "                                       clean_message  \\\n",
       "0  polyscimajor epa chief does not think carbon d...   \n",
       "1  it has it is not like we lack evidence of anth...   \n",
       "2  rt researchers say we have three years to act ...   \n",
       "3  wired  was a pivotal year in the war on climat...   \n",
       "4  rt it has it is  and a racist sexist climate c...   \n",
       "\n",
       "                                              lemmaa  \n",
       "0  polyscimajor epa chief do not think carbon dio...  \n",
       "1  -PRON- have -PRON- be not like -PRON- lack evi...  \n",
       "2  rt researcher say -PRON- have three year to ac...  \n",
       "3  wired   be a pivotal year in the war on climat...  \n",
       "4  rt -PRON- have -PRON- be   and a racist sexist...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2. Removing the PRON and rt form column lemmaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(text):\n",
    "    '''removing the words -PRON- and rt'''\n",
    "    text = re.sub(r'-PRON-','',text)\n",
    "    text = re.sub(r'rt' , '' , text) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>clean_message</th>\n",
       "      <th>lemmaa</th>\n",
       "      <th>clean_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>polyscimajor epa chief does not think carbon d...</td>\n",
       "      <td>polyscimajor epa chief do not think carbon dio...</td>\n",
       "      <td>polyscimajor epa chief do not think carbon dio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>it has it is not like we lack evidence of anth...</td>\n",
       "      <td>-PRON- have -PRON- be not like -PRON- lack evi...</td>\n",
       "      <td>have  be not like  lack evidence of anthropog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>rt researchers say we have three years to act ...</td>\n",
       "      <td>rt researcher say -PRON- have three year to ac...</td>\n",
       "      <td>researcher say  have three year to act on cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>wired  was a pivotal year in the war on climat...</td>\n",
       "      <td>wired   be a pivotal year in the war on climat...</td>\n",
       "      <td>wired   be a pivotal year in the war on climat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>rt it has it is  and a racist sexist climate c...</td>\n",
       "      <td>rt -PRON- have -PRON- be   and a racist sexist...</td>\n",
       "      <td>have  be   and a racist sexist climate chang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "\n",
       "                                       clean_message  \\\n",
       "0  polyscimajor epa chief does not think carbon d...   \n",
       "1  it has it is not like we lack evidence of anth...   \n",
       "2  rt researchers say we have three years to act ...   \n",
       "3  wired  was a pivotal year in the war on climat...   \n",
       "4  rt it has it is  and a racist sexist climate c...   \n",
       "\n",
       "                                              lemmaa  \\\n",
       "0  polyscimajor epa chief do not think carbon dio...   \n",
       "1  -PRON- have -PRON- be not like -PRON- lack evi...   \n",
       "2  rt researcher say -PRON- have three year to ac...   \n",
       "3  wired   be a pivotal year in the war on climat...   \n",
       "4  rt -PRON- have -PRON- be   and a racist sexist...   \n",
       "\n",
       "                                         clean_lemma  \n",
       "0  polyscimajor epa chief do not think carbon dio...  \n",
       "1   have  be not like  lack evidence of anthropog...  \n",
       "2   researcher say  have three year to act on cli...  \n",
       "3  wired   be a pivotal year in the war on climat...  \n",
       "4    have  be   and a racist sexist climate chang...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['clean_lemma'] = train_df['lemmaa'].apply(lambda x: remove(x))\n",
    "test_df['clean_lemma'] = test_df['lemmaa'].apply(lambda x: remove(x))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3. Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def tokenization(text):\n",
    "    '''split the message into taken of words'''\n",
    "    text = word_tokenize(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>clean_message</th>\n",
       "      <th>lemmaa</th>\n",
       "      <th>clean_lemma</th>\n",
       "      <th>tokenized_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>polyscimajor epa chief does not think carbon d...</td>\n",
       "      <td>polyscimajor epa chief do not think carbon dio...</td>\n",
       "      <td>polyscimajor epa chief do not think carbon dio...</td>\n",
       "      <td>[polyscimajor, epa, chief, do, not, think, car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>it has it is not like we lack evidence of anth...</td>\n",
       "      <td>-PRON- have -PRON- be not like -PRON- lack evi...</td>\n",
       "      <td>have  be not like  lack evidence of anthropog...</td>\n",
       "      <td>[have, be, not, like, lack, evidence, of, anth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>rt researchers say we have three years to act ...</td>\n",
       "      <td>rt researcher say -PRON- have three year to ac...</td>\n",
       "      <td>researcher say  have three year to act on cli...</td>\n",
       "      <td>[researcher, say, have, three, year, to, act, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>wired  was a pivotal year in the war on climat...</td>\n",
       "      <td>wired   be a pivotal year in the war on climat...</td>\n",
       "      <td>wired   be a pivotal year in the war on climat...</td>\n",
       "      <td>[wired, be, a, pivotal, year, in, the, war, on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>rt it has it is  and a racist sexist climate c...</td>\n",
       "      <td>rt -PRON- have -PRON- be   and a racist sexist...</td>\n",
       "      <td>have  be   and a racist sexist climate chang...</td>\n",
       "      <td>[have, be, and, a, racist, sexist, climate, ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "\n",
       "                                       clean_message  \\\n",
       "0  polyscimajor epa chief does not think carbon d...   \n",
       "1  it has it is not like we lack evidence of anth...   \n",
       "2  rt researchers say we have three years to act ...   \n",
       "3  wired  was a pivotal year in the war on climat...   \n",
       "4  rt it has it is  and a racist sexist climate c...   \n",
       "\n",
       "                                              lemmaa  \\\n",
       "0  polyscimajor epa chief do not think carbon dio...   \n",
       "1  -PRON- have -PRON- be not like -PRON- lack evi...   \n",
       "2  rt researcher say -PRON- have three year to ac...   \n",
       "3  wired   be a pivotal year in the war on climat...   \n",
       "4  rt -PRON- have -PRON- be   and a racist sexist...   \n",
       "\n",
       "                                         clean_lemma  \\\n",
       "0  polyscimajor epa chief do not think carbon dio...   \n",
       "1   have  be not like  lack evidence of anthropog...   \n",
       "2   researcher say  have three year to act on cli...   \n",
       "3  wired   be a pivotal year in the war on climat...   \n",
       "4    have  be   and a racist sexist climate chang...   \n",
       "\n",
       "                                   tokenized_message  \n",
       "0  [polyscimajor, epa, chief, do, not, think, car...  \n",
       "1  [have, be, not, like, lack, evidence, of, anth...  \n",
       "2  [researcher, say, have, three, year, to, act, ...  \n",
       "3  [wired, be, a, pivotal, year, in, the, war, on...  \n",
       "4  [have, be, and, a, racist, sexist, climate, ch...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['tokenized_message'] = train_df['clean_lemma'].apply(lambda x: tokenization(x.lower()))\n",
    "test_df['tokenized_message'] = test_df['clean_lemma'].apply(lambda x: tokenization(x.lower()))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.4. Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = ['a', 'about', 'above','after', 'again', 'against', 'ain', 'all', \n",
    "        'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', \n",
    "        'be', 'because', 'been', 'before', 'being','below', 'between', \n",
    "        'both', 'but', 'by', 'can', 'couldn',\"couldn't\", 'd', 'did', 'didn', \n",
    "        \"didn't\", 'do', 'does', 'doesn',\"doesn't\", 'doing', 'don', \"don't\",\n",
    "        'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \n",
    "        \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', \n",
    "        'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', \n",
    "        'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', \n",
    "        'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", \n",
    "        'my', 'myself', 'needn', \"needn't\", 'no', 'nor','now', 'o', 'of', 'off', \n",
    "        'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', \n",
    "        're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \n",
    "        \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', \n",
    "        'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', \n",
    "        'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", \n",
    "        'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', \n",
    "        'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \n",
    "        \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word not is kept out of the stop words, this is because the word can help the mechine lean on the negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>clean_message</th>\n",
       "      <th>lemmaa</th>\n",
       "      <th>clean_lemma</th>\n",
       "      <th>tokenized_message</th>\n",
       "      <th>clean_stp_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>polyscimajor epa chief does not think carbon d...</td>\n",
       "      <td>polyscimajor epa chief do not think carbon dio...</td>\n",
       "      <td>polyscimajor epa chief do not think carbon dio...</td>\n",
       "      <td>[polyscimajor, epa, chief, do, not, think, car...</td>\n",
       "      <td>[polyscimajor, epa, chief, not, think, carbon,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>it has it is not like we lack evidence of anth...</td>\n",
       "      <td>-PRON- have -PRON- be not like -PRON- lack evi...</td>\n",
       "      <td>have  be not like  lack evidence of anthropog...</td>\n",
       "      <td>[have, be, not, like, lack, evidence, of, anth...</td>\n",
       "      <td>[not, like, lack, evidence, anthropogenic, glo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>rt researchers say we have three years to act ...</td>\n",
       "      <td>rt researcher say -PRON- have three year to ac...</td>\n",
       "      <td>researcher say  have three year to act on cli...</td>\n",
       "      <td>[researcher, say, have, three, year, to, act, ...</td>\n",
       "      <td>[researcher, say, three, year, act, climate, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>wired  was a pivotal year in the war on climat...</td>\n",
       "      <td>wired   be a pivotal year in the war on climat...</td>\n",
       "      <td>wired   be a pivotal year in the war on climat...</td>\n",
       "      <td>[wired, be, a, pivotal, year, in, the, war, on...</td>\n",
       "      <td>[wired, pivotal, year, war, climate, change]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>rt it has it is  and a racist sexist climate c...</td>\n",
       "      <td>rt -PRON- have -PRON- be   and a racist sexist...</td>\n",
       "      <td>have  be   and a racist sexist climate chang...</td>\n",
       "      <td>[have, be, and, a, racist, sexist, climate, ch...</td>\n",
       "      <td>[racist, sexist, climate, change, deny, bigot,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "\n",
       "                                       clean_message  \\\n",
       "0  polyscimajor epa chief does not think carbon d...   \n",
       "1  it has it is not like we lack evidence of anth...   \n",
       "2  rt researchers say we have three years to act ...   \n",
       "3  wired  was a pivotal year in the war on climat...   \n",
       "4  rt it has it is  and a racist sexist climate c...   \n",
       "\n",
       "                                              lemmaa  \\\n",
       "0  polyscimajor epa chief do not think carbon dio...   \n",
       "1  -PRON- have -PRON- be not like -PRON- lack evi...   \n",
       "2  rt researcher say -PRON- have three year to ac...   \n",
       "3  wired   be a pivotal year in the war on climat...   \n",
       "4  rt -PRON- have -PRON- be   and a racist sexist...   \n",
       "\n",
       "                                         clean_lemma  \\\n",
       "0  polyscimajor epa chief do not think carbon dio...   \n",
       "1   have  be not like  lack evidence of anthropog...   \n",
       "2   researcher say  have three year to act on cli...   \n",
       "3  wired   be a pivotal year in the war on climat...   \n",
       "4    have  be   and a racist sexist climate chang...   \n",
       "\n",
       "                                   tokenized_message  \\\n",
       "0  [polyscimajor, epa, chief, do, not, think, car...   \n",
       "1  [have, be, not, like, lack, evidence, of, anth...   \n",
       "2  [researcher, say, have, three, year, to, act, ...   \n",
       "3  [wired, be, a, pivotal, year, in, the, war, on...   \n",
       "4  [have, be, and, a, racist, sexist, climate, ch...   \n",
       "\n",
       "                                     clean_stp_words  \n",
       "0  [polyscimajor, epa, chief, not, think, carbon,...  \n",
       "1  [not, like, lack, evidence, anthropogenic, glo...  \n",
       "2  [researcher, say, three, year, act, climate, c...  \n",
       "3       [wired, pivotal, year, war, climate, change]  \n",
       "4  [racist, sexist, climate, change, deny, bigot,...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['clean_stp_words'] = train_df['tokenized_message'].apply(lambda x: [item for item in x if item not in stop])\n",
    "test_df['clean_stp_words'] = test_df['tokenized_message'].apply(lambda x: [item for item in x if item not in stop])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.5. Detokinization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer as Detok\n",
    "\n",
    "def detokenization(text):\n",
    "    '''counter slpit the message into taken of words'''\n",
    "    detokenizer = Detok()\n",
    "    text = detokenizer.detokenize(text)\n",
    "    return text\n",
    "train_df['detokenized'] = train_df['clean_stp_words'].apply(lambda x: detokenization(x))\n",
    "test_df['detokenized'] = test_df['clean_stp_words'].apply(lambda x: detokenization(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Creating features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Getting the number of clean words and comparing them with that  raw from the message and clean message columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data frame\n",
    "train_df['Num_words_raw'] = train_df['message'].apply(lambda x:len(str(x).split())) \n",
    "train_df['Num_words_clean'] = train_df['clean_message'].apply(lambda x:len(str(x).split()))\n",
    "#Difference in Number of words text and Selected Text\n",
    "train_df['difference_in_wordsNo'] = abs(train_df['Num_words_raw'] - train_df['Num_words_clean']) \n",
    "#test data frame\n",
    "test_df['Num_words_raw'] = test_df['message'].apply(lambda x:len(str(x).split())) \n",
    "test_df['Num_words_clean'] = test_df['clean_message'].apply(lambda x:len(str(x).split())) \n",
    "#Difference in Number of words text and Selected Text\n",
    "test_df['difference_in_wordsNo'] = abs(test_df['Num_words_raw'] - test_df['Num_words_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(4)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "two columns are created to show the total number of words before and after cleaning to gether with thier differences in words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Jaccard score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1. Jaccard score compares members for two sets to see which members are shared and which are distinct. It's a measure of similarity for the two sets of data, with a range from 0% to 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    '''It takes two strings can be two columns fro a df and returns intersection of twe two  divided by thier union'''\n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the train_df\n",
    "results_jaccard=[]\n",
    "\n",
    "for ind,row in train_df.iterrows():\n",
    "    sentence1 = row.message\n",
    "    sentence2 = row.clean_message\n",
    "\n",
    "    jaccard_score = jaccard(sentence1,sentence2)\n",
    "    results_jaccard.append([sentence1,sentence2,jaccard_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the jaccard score to the main data frame\n",
    "jaccard = pd.DataFrame(results_jaccard,columns=[\"message\",\"clean_message\",\"jaccard_score\"])\n",
    "train_df = train_df.merge(jaccard,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Exploratory Data Analysis on Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. Word Visualization of clean tweet messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_colwidth', 60)\n",
    "# visualising the clean messages \n",
    "df_senti1 = train_df[train_df['sentiment']==1]\n",
    "df_senti0 = train_df[train_df['sentiment']==0]\n",
    "df_senti_neg1 = train_df[train_df['sentiment']==-1]\n",
    "df_senti2 = train_df[train_df['sentiment']==2]\n",
    "tweet_All = \" \".join(review for review in train_df.detokenized)\n",
    "tweet_senti1 = \" \".join(review for review in df_senti1.detokenized)\n",
    "tweet_senti0 = \" \".join(review for review in df_senti0.detokenized)\n",
    "tweet_senti_neg1 = \" \".join(review for review in df_senti_neg1.detokenized)\n",
    "tweet_senti2 = \" \".join(review for review in df_senti2.detokenized)\n",
    "\n",
    "fig, ax = plt.subplots(5, 1, figsize  = (65,65))\n",
    "# Create and generate a word cloud image:\n",
    "wordcloud_ALL = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_All)\n",
    "wordcloud_1 = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_senti1)\n",
    "wordcloud_0 = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_senti0)\n",
    "wordcloud_neg1 = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_senti_neg1)\n",
    "wordcloud_2 = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_senti2)\n",
    "\n",
    "# Display the generated image:\n",
    "ax[0].imshow(wordcloud_ALL, interpolation='bilinear')\n",
    "ax[0].set_title('All Tweets', fontsize=50)\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(wordcloud_1, interpolation='bilinear')\n",
    "ax[1].set_title('Tweets under Pro Class 1',fontsize=50)\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(wordcloud_0, interpolation='bilinear')\n",
    "ax[2].set_title('Tweets under Neutral Class 0',fontsize=50)\n",
    "ax[2].axis('off')\n",
    "ax[3].imshow(wordcloud_neg1, interpolation='bilinear')\n",
    "ax[3].set_title('Tweets under Anti Class -1',fontsize=50)\n",
    "ax[3].axis('off')\n",
    "ax[4].imshow(wordcloud_2, interpolation='bilinear')\n",
    "ax[4].set_title('Tweets under News Class 2',fontsize=50)\n",
    "ax[4].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. Most Common words in clean message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['temp_list0'] = train_df['detokenized'].apply(lambda x:str(x).split())\n",
    "top = Counter([item for sublist in train_df['temp_list0'] for item in sublist])\n",
    "temp0 = pd.DataFrame(top.most_common(20))\n",
    "temp0.columns = ['Common_words','count']\n",
    "temp0.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(temp0, x=\"count\", y=\"Common_words\", title='Commmon Words in cleaned message', orientation='h', \n",
    "             width=700, height=700,color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3. Most common words sentiment wise in clean message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the sentiments so that each sentiment can be explored\n",
    "Pro = train_df[train_df['sentiment']==1]\n",
    "Anti = train_df[train_df['sentiment']== -1]\n",
    "Neutral = train_df[train_df['sentiment']==0]\n",
    "News = train_df[train_df['sentiment']== 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MosT common positive words(Pro)\n",
    "top = Counter([item for sublist in Pro['temp_list0'] for item in sublist])\n",
    "temp_positive = pd.DataFrame(top.most_common(20))\n",
    "temp_positive.columns = ['Common_words','count']\n",
    "temp_positive.style.background_gradient(cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MosT common words in Neutral sentiment\n",
    "top = Counter([item for sublist in Neutral['temp_list0'] for item in sublist])\n",
    "temp_neutral = pd.DataFrame(top.most_common(20))\n",
    "temp_neutral = temp_neutral.loc[1:,:]\n",
    "temp_neutral.columns = ['Common_words','count']\n",
    "temp_neutral.style.background_gradient(cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MosT common words in Neutral sentiment\n",
    "top = Counter([item for sublist in Neutral['temp_list0'] for item in sublist])\n",
    "temp_neutral = pd.DataFrame(top.most_common(20))\n",
    "temp_neutral = temp_neutral.loc[1:,:]\n",
    "temp_neutral.columns = ['Common_words','count']\n",
    "temp_neutral.style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MosT common words in News sentiment\n",
    "top = Counter([item for sublist in News['temp_list0'] for item in sublist])\n",
    "temp_neutral = pd.DataFrame(top.most_common(20))\n",
    "temp_neutral = temp_neutral.loc[1:,:]\n",
    "temp_neutral.columns = ['Common_words','count']\n",
    "temp_neutral.style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4. Number of raw and clean message columns  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Below is modeling of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. SUPPORT VECTOR MACHINES/CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of a Linear SVC (Support Vector Classifier) is to fit to the data provided, returning a \"best fit\" hyperplane that categorizes data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer as Detok\n",
    "import sklearn.metrics as metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building pipelines to vectorize the data, then train and fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVC:\n",
    "text_clf_lsvc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defing the x and y varible\n",
    "X= train_df['message']\n",
    "y=train_df['sentiment']\n",
    "# slpitting the X and y into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Linear SVC:\n",
    "text_clf_lsvc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "])\n",
    "text_clf_lsvc.fit(X_train, y_train)\n",
    "# Form a prediction set\n",
    "predictions = text_clf_lsvc.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions))\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on clean message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 121   35  112   10]\n",
      " [  24  180  187   34]\n",
      " [  36  107 1461  151]\n",
      " [   9   23  159  515]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.44      0.52       278\n",
      "           0       0.52      0.42      0.47       425\n",
      "           1       0.76      0.83      0.80      1755\n",
      "           2       0.73      0.73      0.73       706\n",
      "\n",
      "    accuracy                           0.72      3164\n",
      "   macro avg       0.66      0.61      0.63      3164\n",
      "weighted avg       0.71      0.72      0.71      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defing the x and y varible\n",
    "X= train_df['detokenized']\n",
    "y=train_df['sentiment']\n",
    "# slpitting the X and y into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Linear SVC:\n",
    "text_clf_lsvc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "])\n",
    "text_clf_lsvc.fit(X_train, y_train)\n",
    "# Form a prediction set\n",
    "predictions = text_clf_lsvc.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions))\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_lsvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, file_name):\n",
    "    model_save_path = file_name+\".pkl\"\n",
    "    with open(model_save_path, 'wb') as file:\n",
    "        pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name  = 'saved_model_for_App'\n",
    "save_model(text_clf_lsvc, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(file_name):\n",
    "    model_load_path = file_name+\".pkl\"\n",
    "    with open(model_load_path, 'rb') as file:\n",
    "        unpickled_model = pickle.load(file)\n",
    "    return unpickled_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(file_name)\n",
    "y_pred = loaded_model.predict([train_df['detokenized'][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'researcher say three year act climate change late'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['detokenized'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on clean message without retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing any repeated messages while keeping the first of those messages\n",
    "new_df = train_df.drop_duplicates(subset=['detokenized'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defing the x and y varible\n",
    "X= new_df['detokenized']\n",
    "y=new_df['sentiment']\n",
    "# slpitting the X and y into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Feeding the training data through the Linear SVC pipeline\n",
    "text_clf_lsvc.fit(X_train, y_train)\n",
    "# Form a prediction set\n",
    "dtknz_pred = text_clf_lsvc.predict(X_test)\n",
    "# Report the confusion matrix\n",
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test,dtknz_pred))\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,dtknz_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all of the above Trainings, the model is better at predicting class 1, this is due to imbalance in classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling the majority classes\n",
    "\n",
    "Since the class Pro(1),News (2) and Neutral(0) has so many observations, thier sizes will be reduced by taking a small random subset of observations to match the size of the class Anti(-1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the sentiments\n",
    "Pro = train_df[train_df['sentiment']==1]\n",
    "Anti = train_df[train_df['sentiment']== -1]\n",
    "Neutral = train_df[train_df['sentiment']==0]\n",
    "News = train_df[train_df['sentiment']== 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample majority\n",
    "Pro_downsampled = resample(Pro,\n",
    "                          replace=False, # sample without replacement (no need to duplicate observations)\n",
    "                          n_samples=len(Anti), # match number in minority class\n",
    "                          random_state=27) # reproducible results\n",
    "Neutral_downsampled = resample(Neutral,\n",
    "                          replace=False, # sample without replacement (no need to duplicate observations)\n",
    "                          n_samples=len(Anti), # match number in minority class\n",
    "                          random_state=27) # reproducible results\n",
    "News_downsampled = resample(News,\n",
    "                          replace=False, # sample without replacement (no need to duplicate observations)\n",
    "                          n_samples=len(Anti), # match number in minority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "\n",
    "\n",
    "# Combine downsampled majority class with minority class\n",
    "downsampled = pd.concat([Pro_downsampled,Neutral_downsampled,News_downsampled,Anti])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = downsampled.groupby('sentiment').count()['message'].reset_index().sort_values(by='message',ascending=False)\n",
    "temp['percentage'] = (temp['message']/temp['message'].sum())*100\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the sentiments are balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on downsampled clean message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defing the x and y varible\n",
    "X= downsampled['detokenized']\n",
    "y=downsampled['sentiment']\n",
    "# slpitting the X and y into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Linear SVC:\n",
    "text_clf_lsvc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "])\n",
    "text_clf_lsvc.fit(X_train, y_train)\n",
    "# Form a prediction set\n",
    "predictions = text_clf_lsvc.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions))\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score has improved a lot, now all sentiments have better score above 74%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df['detokenized']\n",
    "down_s_pred= text_clf_lsvc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_s_pred = pd.DataFrame(data=down_s_pred,\n",
    "                                 columns=['sentiment'],\n",
    "                                 index=test_df['tweetid'])\n",
    "down_s_pred.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_s_pred.to_csv(r\"C:\\Users\\elton\\Documents\\Jm_team\\Classification_Predict_Package\\predictions_SVC\\down_s_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Downsampling the dataframe(new_df) without the retweets and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the sentiments\n",
    "Pro = new_df[new_df['sentiment']==1]\n",
    "Anti = new_df[new_df['sentiment']== -1]\n",
    "Neutral = new_df[new_df['sentiment']==0]\n",
    "News = new_df[new_df['sentiment']== 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample majority\n",
    "Pro_downsampled = resample(Pro,\n",
    "                          replace=False, # sample without replacement (no need to duplicate observations)\n",
    "                          n_samples=len(Anti), # match number in minority class\n",
    "                          random_state=27) # reproducible results\n",
    "Neutral_downsampled = resample(Neutral,\n",
    "                          replace=False, # sample without replacement (no need to duplicate observations)\n",
    "                          n_samples=len(Anti), # match number in minority class\n",
    "                          random_state=27) # reproducible results\n",
    "News_downsampled = resample(News,\n",
    "                          replace=False, # sample without replacement (no need to duplicate observations)\n",
    "                          n_samples=len(Anti), # match number in minority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "\n",
    "\n",
    "# Combine downsampled majority class with minority class\n",
    "downsampled2 = pd.concat([Pro_downsampled,Neutral_downsampled,News_downsampled,Anti])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = downsampled2.groupby('sentiment').count()['message'].reset_index().sort_values(by='message',ascending=False)\n",
    "temp['percentage'] = (temp['message']/temp['message'].sum())*100\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it is observable that the classes have reduced since the retweets were dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defing the x and y varible\n",
    "X= downsampled2['detokenized']\n",
    "y=downsampled2['sentiment']\n",
    "# slpitting the X and y into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Linear SVC:\n",
    "text_clf_lsvc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "])\n",
    "text_clf_lsvc.fit(X_train, y_train)\n",
    "# Form a prediction set\n",
    "predictions = text_clf_lsvc.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions))\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the model now is perfoming worse, this may be because the model is underfed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SMOTE Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import *\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import SMOTE module from imblearn library \n",
    "# pip install imblearn (if you don't have imblearn in your system) \n",
    "from imblearn.over_sampling import SMOTE\n",
    "# defing the x and y varible\n",
    "X= train_df['detokenized']\n",
    "y=train_df['sentiment']\n",
    " \n",
    "sm = SMOTE(random_state = 2) \n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(X)\n",
    "X, y = sm.fit_sample(X, y.ravel()) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_lsvc = Pipeline([('clf', LinearSVC())])\n",
    "text_clf_lsvc.fit(X_train, y_train)\n",
    "# Form a prediction set\n",
    "predictions = text_clf_lsvc.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions))\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the Time_from_Pickup_to_Arrival with unseen x test\n",
    "X_test = test_df['detokenized']\n",
    "X_test = tfidf_vectorizer.fit_transform(X_test)\n",
    "#smote_pred = text_clf_lsvc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smote without retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import SMOTE module from imblearn library \n",
    "# pip install imblearn (if you don't have imblearn in your system) \n",
    "from imblearn.over_sampling import SMOTE\n",
    "# defing the x and y varible\n",
    "X= new_df['detokenized']\n",
    "y=new_df['sentiment']\n",
    " \n",
    "sm = SMOTE(random_state = 2) \n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(X)\n",
    "X, y = sm.fit_sample(X, y.ravel()) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_lsvc = Pipeline([('clf', LinearSVC())])\n",
    "text_clf_lsvc.fit(X_train, y_train)\n",
    "# Form a prediction set\n",
    "predictions = text_clf_lsvc.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions))\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
